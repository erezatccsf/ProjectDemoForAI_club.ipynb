{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ProjectDemoForAI_club.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/erezatccsf/ProjectDemoForAI_club.ipynb/blob/master/ProjectDemoForAI_club.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5da-78c2rG-",
        "colab_type": "text"
      },
      "source": [
        "Craig Persiko<br>\n",
        "Project Demo Presentation for CCSF AI Club, based on:<br>\n",
        "Data Science Principles and Practices Using Python<br>\n",
        "UC Berkeley Extension<br>\n",
        "Our class used the following textbook, which is available for free at:\n",
        "https://jakevdp.github.io/PythonDataScienceHandbook/ <br>\n",
        "Final Project, due 4/7/2020<br>\n",
        "Analysis of how Random Forest and simple Decision Tree predictive models work with 4 different data sets, and deeper analysis of my assignment 2 solution (IMDB Data Set movie ratings prediction).<p>\n",
        "\n",
        "This project started with Assignment 2 from the class, which is detailed here: https://docs.google.com/document/d/1EmFtIgqZRCAa5-q3wRSH7Kk388FRcabNbbshMSbpDEs/edit?usp=sharing\n",
        "My code for the solution of this assignment follows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEFNdBJeeRZ8",
        "colab_type": "code",
        "outputId": "74cd2577-0aea-4d1d-b0ef-e8110647da54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 482
        }
      },
      "source": [
        "# Craig Persiko\n",
        "# IMDB dataset rating prediction\n",
        "# This first code block begins my solution to Assignment 2. \n",
        "# See the last code block for the Tree analysis.\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Part 1: Data Set Generation 15%\n",
        "# Join two other sources (e.g. title.crew.tsv.gz, title.basics.tsv.gz, etc) to make some meaningful features for rating prediction.\n",
        "# Only consider movies with startYear  after 1980 (including 1980)\n",
        "\n",
        "def convertToInt(val):\n",
        "  try:\n",
        "    return np.int16(val)\n",
        "  except:\n",
        "    return np.int16(0)  \n",
        "\n",
        "df_ratings = pd.read_csv(\"https://datasets.imdbws.com/title.ratings.tsv.gz\", sep='\\t')\n",
        "df_crew = pd.read_csv(\"https://datasets.imdbws.com/title.crew.tsv.gz\", sep='\\t')\n",
        "df_basics = pd.read_csv(\"https://datasets.imdbws.com/title.basics.tsv.gz\", sep='\\t', dtype=\"str\", converters={'startYear':convertToInt})\n",
        "\n",
        "df_ratingsCrew = pd.merge(df_ratings, df_crew)\n",
        "df_fullData = pd.merge(df_ratingsCrew, df_basics)\n",
        "\n",
        "columnsToKeep = ['tconst', 'titleType', 'primaryTitle', 'averageRating', 'startYear', 'genres', 'directors']\n",
        "df_selectedData = df_fullData.loc[df_fullData.startYear >= 1980 , columnsToKeep]\n",
        "df_selectedData.dropna()\n",
        "\n",
        "print(\"Data for all titles after 1980 has shape:\", df_selectedData.shape)\n",
        "print(\"and here are the first few rows:\")\n",
        "display(df_selectedData)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:17: ParserWarning: Both a converter and dtype were specified for column startYear - only the converter will be used\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Data for all titles after 1980 has shape: (864873, 7)\n",
            "and here are the first few rows:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tconst</th>\n",
              "      <th>titleType</th>\n",
              "      <th>primaryTitle</th>\n",
              "      <th>averageRating</th>\n",
              "      <th>startYear</th>\n",
              "      <th>genres</th>\n",
              "      <th>directors</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4029</th>\n",
              "      <td>tt0015724</td>\n",
              "      <td>movie</td>\n",
              "      <td>Dama de noche</td>\n",
              "      <td>6.2</td>\n",
              "      <td>1993</td>\n",
              "      <td>Drama,Mystery,Romance</td>\n",
              "      <td>nm0529960</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4475</th>\n",
              "      <td>tt0016906</td>\n",
              "      <td>movie</td>\n",
              "      <td>Frivolinas</td>\n",
              "      <td>5.6</td>\n",
              "      <td>2014</td>\n",
              "      <td>Comedy,Musical</td>\n",
              "      <td>nm0136068</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5028</th>\n",
              "      <td>tt0018295</td>\n",
              "      <td>short</td>\n",
              "      <td>El puño de hierro</td>\n",
              "      <td>6.7</td>\n",
              "      <td>2004</td>\n",
              "      <td>Action,Drama,Short</td>\n",
              "      <td>nm0305771</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17176</th>\n",
              "      <td>tt0035423</td>\n",
              "      <td>movie</td>\n",
              "      <td>Kate &amp; Leopold</td>\n",
              "      <td>6.4</td>\n",
              "      <td>2001</td>\n",
              "      <td>Comedy,Fantasy,Romance</td>\n",
              "      <td>nm0003506</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18140</th>\n",
              "      <td>tt0036606</td>\n",
              "      <td>movie</td>\n",
              "      <td>Another Time, Another Place</td>\n",
              "      <td>6.5</td>\n",
              "      <td>1983</td>\n",
              "      <td>Drama,War</td>\n",
              "      <td>nm0705535</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1030403</th>\n",
              "      <td>tt9916576</td>\n",
              "      <td>tvEpisode</td>\n",
              "      <td>Destinee's Story</td>\n",
              "      <td>6.0</td>\n",
              "      <td>2019</td>\n",
              "      <td>Reality-TV</td>\n",
              "      <td>\\N</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1030404</th>\n",
              "      <td>tt9916578</td>\n",
              "      <td>tvEpisode</td>\n",
              "      <td>The Trial of Joan Collins</td>\n",
              "      <td>8.4</td>\n",
              "      <td>2019</td>\n",
              "      <td>Adventure,Biography,Comedy</td>\n",
              "      <td>nm0373673</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1030405</th>\n",
              "      <td>tt9916720</td>\n",
              "      <td>short</td>\n",
              "      <td>The Nun 2</td>\n",
              "      <td>5.6</td>\n",
              "      <td>2019</td>\n",
              "      <td>Comedy,Horror,Mystery</td>\n",
              "      <td>nm10538600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1030406</th>\n",
              "      <td>tt9916766</td>\n",
              "      <td>tvEpisode</td>\n",
              "      <td>Episode #10.15</td>\n",
              "      <td>6.8</td>\n",
              "      <td>2019</td>\n",
              "      <td>Family,Reality-TV</td>\n",
              "      <td>\\N</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1030407</th>\n",
              "      <td>tt9916778</td>\n",
              "      <td>tvEpisode</td>\n",
              "      <td>Escape</td>\n",
              "      <td>7.2</td>\n",
              "      <td>2019</td>\n",
              "      <td>Drama</td>\n",
              "      <td>\\N</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>864873 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            tconst  titleType  ...                      genres   directors\n",
              "4029     tt0015724      movie  ...       Drama,Mystery,Romance   nm0529960\n",
              "4475     tt0016906      movie  ...              Comedy,Musical   nm0136068\n",
              "5028     tt0018295      short  ...          Action,Drama,Short   nm0305771\n",
              "17176    tt0035423      movie  ...      Comedy,Fantasy,Romance   nm0003506\n",
              "18140    tt0036606      movie  ...                   Drama,War   nm0705535\n",
              "...            ...        ...  ...                         ...         ...\n",
              "1030403  tt9916576  tvEpisode  ...                  Reality-TV          \\N\n",
              "1030404  tt9916578  tvEpisode  ...  Adventure,Biography,Comedy   nm0373673\n",
              "1030405  tt9916720      short  ...       Comedy,Horror,Mystery  nm10538600\n",
              "1030406  tt9916766  tvEpisode  ...           Family,Reality-TV          \\N\n",
              "1030407  tt9916778  tvEpisode  ...                       Drama          \\N\n",
              "\n",
              "[864873 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_EoVGSTOgbs2",
        "colab_type": "code",
        "outputId": "b13bc3de-0d10-4f5e-d8ad-a81ea377a14c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 679
        }
      },
      "source": [
        "# Part 2: Modeling 15%\n",
        "# Train/Dev/Test random split = 80/10/10\n",
        "# Model the problem as 3-class multiclass classification:\n",
        "# Very Good: >7\n",
        "# Good: 3.5 < x < 6.5\n",
        "# Bad: < 3\n",
        "\n",
        "# Setting up named constants for our 3 classes:\n",
        "veryGood = 2\n",
        "good = 1\n",
        "bad = 0\n",
        "\n",
        "df_veryGood = df_selectedData.query('averageRating > 7')\n",
        "df_veryGood = df_veryGood.eval('averageRating = @veryGood')\n",
        "\n",
        "df_good = df_selectedData.query('3.5 < averageRating < 6.5')\n",
        "df_good = df_good.eval('averageRating = @good')\n",
        "\n",
        "df_bad = df_selectedData.query('averageRating < 3')\n",
        "df_bad = df_bad.eval('averageRating = @bad')\n",
        "\n",
        "df_classifiedData = pd.concat([df_veryGood, df_good, df_bad])\n",
        "\n",
        "print(\"Data with just 3 classes for ratings has shape:\", df_classifiedData.shape)\n",
        "\n",
        "# Code all features with numeric values\n",
        "import hashlib\n",
        "\n",
        "df_classifiedData['hashed_directors'] = df_classifiedData['directors'].apply(lambda x: int(hashlib.sha1(x.encode()).hexdigest(), 16) % (100))\n",
        "df_classifiedData['hashed_genres'] = df_classifiedData['genres'].apply(lambda x: int(hashlib.sha1(str(x).encode()).hexdigest(), 16) % (100))\n",
        "df_classifiedData['hashed_type'] = df_classifiedData['titleType'].apply(lambda x: int(hashlib.sha1(str(x).encode()).hexdigest(), 16) % (100))\n",
        "\n",
        "# Train/Dev/Test random split = 80/10/10\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "df_train, df_dev = train_test_split(df_classifiedData, test_size=0.2)\n",
        "df_dev, df_test = train_test_split(df_dev, test_size=0.5)\n",
        "\n",
        "print(\"Training data with hashed features has shape:\", df_train.shape)\n",
        "print(\"Dev data with hashed features has shape:\", df_dev.shape)\n",
        "print(\"Test data with hashed features has shape:\", df_test.shape)\n",
        "\n",
        "# Train the model\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "dtModel = DecisionTreeClassifier()\n",
        "rfModel = RandomForestClassifier()\n",
        "\n",
        "featureColumns = ['hashed_type', 'startYear', 'hashed_genres', 'hashed_directors']\n",
        "X_train = df_train.loc[:, featureColumns]\n",
        "y_train = df_train.averageRating\n",
        "X_dev = df_dev.loc[:, featureColumns]\n",
        "y_dev = df_dev.averageRating\n",
        "X_test = df_test.loc[:, featureColumns]\n",
        "y_test = df_test.averageRating\n",
        "\n",
        "dtModel.fit(X_train, y_train)\n",
        "print(\"Decision Tree Training accuracy:\", dtModel.score(X_train, y_train)) \n",
        "print(\"Decision Tree Dev accuracy:\", dtModel.score(X_dev, y_dev)) \n",
        "print(\"Decision Tree Test accuracy:\", dtModel.score(X_test, y_test))\n",
        "\n",
        "rfModel.fit(X_train, y_train)\n",
        "print(\"Random Forest Training accuracy:\", rfModel.score(X_train, y_train)) \n",
        "print(\"Random Forest Dev accuracy:\", rfModel.score(X_dev, y_dev)) \n",
        "print(\"Random Forest Test accuracy:\", rfModel.score(X_test, y_test))\n",
        "\n",
        "print(\"Samples of processed test data set:\")\n",
        "display(df_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data with just 3 classes for ratings has shape: (714030, 7)\n",
            "Training data with hashed features has shape: (571224, 10)\n",
            "Dev data with hashed features has shape: (71403, 10)\n",
            "Test data with hashed features has shape: (71403, 10)\n",
            "Decision Tree Training accuracy: 0.8733981765472039\n",
            "Decision Tree Dev accuracy: 0.7074352618237328\n",
            "Decision Tree Test accuracy: 0.7078974272789659\n",
            "Random Forest Training accuracy: 0.8733771690265115\n",
            "Random Forest Dev accuracy: 0.7247594638880719\n",
            "Random Forest Test accuracy: 0.7249555340812011\n",
            "Samples of processed test data set:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tconst</th>\n",
              "      <th>titleType</th>\n",
              "      <th>primaryTitle</th>\n",
              "      <th>averageRating</th>\n",
              "      <th>startYear</th>\n",
              "      <th>genres</th>\n",
              "      <th>directors</th>\n",
              "      <th>hashed_directors</th>\n",
              "      <th>hashed_genres</th>\n",
              "      <th>hashed_type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>960800</th>\n",
              "      <td>tt7590152</td>\n",
              "      <td>tvEpisode</td>\n",
              "      <td>Episode #2.5</td>\n",
              "      <td>0</td>\n",
              "      <td>2017</td>\n",
              "      <td>Reality-TV</td>\n",
              "      <td>\\N</td>\n",
              "      <td>75</td>\n",
              "      <td>47</td>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>581508</th>\n",
              "      <td>tt1635830</td>\n",
              "      <td>tvEpisode</td>\n",
              "      <td>Liars</td>\n",
              "      <td>2</td>\n",
              "      <td>2011</td>\n",
              "      <td>Comedy,Drama,Romance</td>\n",
              "      <td>nm0318795</td>\n",
              "      <td>60</td>\n",
              "      <td>33</td>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>654995</th>\n",
              "      <td>tt2145570</td>\n",
              "      <td>tvSeries</td>\n",
              "      <td>In Reverie</td>\n",
              "      <td>2</td>\n",
              "      <td>2012</td>\n",
              "      <td>Drama</td>\n",
              "      <td>nm3637034</td>\n",
              "      <td>28</td>\n",
              "      <td>71</td>\n",
              "      <td>55</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>457303</th>\n",
              "      <td>tt10749672</td>\n",
              "      <td>movie</td>\n",
              "      <td>A Planet in the Sea</td>\n",
              "      <td>1</td>\n",
              "      <td>2019</td>\n",
              "      <td>Documentary</td>\n",
              "      <td>nm3113346</td>\n",
              "      <td>21</td>\n",
              "      <td>61</td>\n",
              "      <td>56</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>767377</th>\n",
              "      <td>tt3687564</td>\n",
              "      <td>videoGame</td>\n",
              "      <td>Animaniacs</td>\n",
              "      <td>2</td>\n",
              "      <td>1994</td>\n",
              "      <td>Action</td>\n",
              "      <td>nm2120354</td>\n",
              "      <td>14</td>\n",
              "      <td>18</td>\n",
              "      <td>72</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>382948</th>\n",
              "      <td>tt0825900</td>\n",
              "      <td>tvEpisode</td>\n",
              "      <td>After the Fall</td>\n",
              "      <td>2</td>\n",
              "      <td>1987</td>\n",
              "      <td>Comedy</td>\n",
              "      <td>nm0694516</td>\n",
              "      <td>34</td>\n",
              "      <td>31</td>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>819159</th>\n",
              "      <td>tt4659808</td>\n",
              "      <td>movie</td>\n",
              "      <td>The Wolf's Lair</td>\n",
              "      <td>2</td>\n",
              "      <td>2015</td>\n",
              "      <td>Biography,Documentary,Family</td>\n",
              "      <td>nm0610041</td>\n",
              "      <td>12</td>\n",
              "      <td>56</td>\n",
              "      <td>56</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>234499</th>\n",
              "      <td>tt0446975</td>\n",
              "      <td>short</td>\n",
              "      <td>Les couilles de mon chat</td>\n",
              "      <td>1</td>\n",
              "      <td>2005</td>\n",
              "      <td>Action,Comedy,Short</td>\n",
              "      <td>nm0126875</td>\n",
              "      <td>55</td>\n",
              "      <td>38</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>620589</th>\n",
              "      <td>tt1872194</td>\n",
              "      <td>movie</td>\n",
              "      <td>The Judge</td>\n",
              "      <td>2</td>\n",
              "      <td>2014</td>\n",
              "      <td>Crime,Drama</td>\n",
              "      <td>nm0229694</td>\n",
              "      <td>85</td>\n",
              "      <td>34</td>\n",
              "      <td>56</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>918185</th>\n",
              "      <td>tt6560136</td>\n",
              "      <td>tvEpisode</td>\n",
              "      <td>Hide and Seek</td>\n",
              "      <td>2</td>\n",
              "      <td>2018</td>\n",
              "      <td>Comedy,Drama,Fantasy</td>\n",
              "      <td>nm0687964</td>\n",
              "      <td>38</td>\n",
              "      <td>70</td>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>71403 rows × 10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            tconst  titleType  ... hashed_genres  hashed_type\n",
              "960800   tt7590152  tvEpisode  ...            47           35\n",
              "581508   tt1635830  tvEpisode  ...            33           35\n",
              "654995   tt2145570   tvSeries  ...            71           55\n",
              "457303  tt10749672      movie  ...            61           56\n",
              "767377   tt3687564  videoGame  ...            18           72\n",
              "...            ...        ...  ...           ...          ...\n",
              "382948   tt0825900  tvEpisode  ...            31           35\n",
              "819159   tt4659808      movie  ...            56           56\n",
              "234499   tt0446975      short  ...            38           14\n",
              "620589   tt1872194      movie  ...            34           56\n",
              "918185   tt6560136  tvEpisode  ...            70           35\n",
              "\n",
              "[71403 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ub4Kq0AzzoI-",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "* In my Assignment 2 solution, I used a Random Forest model to predict film ratings, with pretty good results: 73% accuracy. When I used a single Decision Tree, I got just 71% accuracy, but with a much shorter run-time. (See code above)\n",
        "\n",
        "* In the following Kaggle submission, the author used a Random Forest model to predict heart disease, getting 82% accuracy, whereas a single Decision Tree model only got 78% accuracy:\n",
        "https://www.kaggle.com/faressayah/predicting-heart-disease-using-machine-learning#4.-Applying-machine-learning-algorithms\n",
        "\n",
        "* In this Kaggle submission, the author used a Random Forest for 85% accuracy and also a simple Decision Tree for 84% accuracy to predict individuals' survival on the Titanic:\n",
        "https://www.kaggle.com/ihelon/tree-randomforest-xgboost-lightgbm-catboost\n",
        "\n",
        "* In another Kaggle submission, the author used a Random Forest model to predict happiness, again getting better accuracy than with a single Decision Tree. (This one is programmed in R):\n",
        "https://www.kaggle.com/javadzabihi/happiness-2017-visualization-prediction\n",
        "\n",
        "\n",
        "So I decided to investigate more about Random Forests and Decision Trees. I found a couple of Kaggles with great explanations.  **Here's an excellent overview:**\n",
        "https://www.kaggle.com/faressayah/decision-trees-and-random-forest-tutorial\n",
        "\n",
        "And this one has **more technical detail and some great tree diagrams derived from the actual trees** that were generated by the code and data: https://www.kaggle.com/akashram/demystify-the-random-forest\n",
        "<p>\n",
        "This led me back to my Assignment 2 solution,\n",
        "where I added code, trying to do similar visualizations, but instead came up with some quantitative information about the trees that were generated. (See below)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KyxYUPaG4Q2s",
        "colab_type": "text"
      },
      "source": [
        "#Here is my analysis of the trees used in my assignment 2 solution above:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzxqx-z9hL08",
        "colab_type": "code",
        "outputId": "313db411-48d1-4b66-a388-3c88e8b7edd3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# The following code was inspired by https://www.kaggle.com/akashram/demystify-the-random-forest\n",
        "# but I ran out of RAM when I tried to run it.  The below analysis will show you why:\n",
        "#from IPython.display import Image\n",
        "#from sklearn.tree import export_graphviz\n",
        "#import pydotplus\n",
        "#dot_data = StringIO()\n",
        "#export_graphviz(dtModel, out_file=dot_data,  \n",
        "#                filled=True, rounded=True,\n",
        "#                special_characters=True)\n",
        "#graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
        "#Image(graph.create_png())\n",
        "\n",
        "!pip install treeinterpreter\n",
        "from treeinterpreter import treeinterpreter as ti\n",
        "\n",
        "exampleIndex = 2 # 0\n",
        "\n",
        "print()\n",
        "print(\"Feature columns are:\", featureColumns)\n",
        "print(\"Looking at one row of features as an example:\")\n",
        "sampleRow = X_test.iloc[exampleIndex].to_numpy().reshape(1, -1)\n",
        "print(sampleRow)\n",
        "print(\"Its correct rating code (range is 0, 1, or 2) is:\", y_test.iloc[exampleIndex])\n",
        "print()\n",
        "  \n",
        "def analyzeTree(dt, description):\n",
        "  ''' \n",
        "  function to print out quantitative info and a sample prediction\n",
        "  for the decision tree dt, with its description\n",
        "  '''\n",
        "  print(description, \"has a depth of:\", dt.get_depth())\n",
        "  print(description, \"has:\", dt.get_n_leaves(), \"leaves.\")\n",
        "  print(\"For our example row shown at top...\")\n",
        "  print(\"The correct rating code (range is 0, 1, or 2) is:\", y_test.iloc[exampleIndex])\n",
        "  print(\"The tree's prediction is:\", dt.predict(sampleRow))\n",
        "  print(\"which is derived from the following probabilities from training data:\", dt.predict_proba(sampleRow))\n",
        "  prediction, bias, contributions = ti.predict(dt, sampleRow)\n",
        "  print(\"Its prediction probabilities of\", prediction, \"are calculated by adding the bias of\", bias)\n",
        "  print(\"to the following contributions, along each column (one per feature):\")\n",
        "  print(contributions)\n",
        "  print(\"Calculated prediction is:\", bias + np.sum(contributions, axis=1))\n",
        "  print(description, \"has the following feature importances overall:\", dt.feature_importances_)\n",
        "\n",
        "analyzeTree(dtModel, \"Decision tree (simple)\")\n",
        "print()\n",
        "print(\"For the same example row shown at top, the Random Forest's overall prediction is:\", rfModel.predict(sampleRow))\n",
        "rfEstimators = rfModel.estimators_\n",
        "print(\"By majority vote of its\", len(rfEstimators), \"trees. Here are the first 10:\")\n",
        "print()\n",
        "count = 1\n",
        "for treeFromForest in rfEstimators[:10]:\n",
        "  analyzeTree(treeFromForest, \"Sample tree #\"+str(count)+\" from forest\")\n",
        "  count = count + 1\n",
        "  print()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: treeinterpreter in /usr/local/lib/python3.6/dist-packages (0.2.2)\n",
            "\n",
            "Feature columns are: ['hashed_type', 'startYear', 'hashed_genres', 'hashed_directors']\n",
            "Looking at one row of features as an example:\n",
            "[[  55 2012   71   28]]\n",
            "Its correct rating code (range is 0, 1, or 2) is: 2\n",
            "\n",
            "Decision tree (simple) has a depth of: 45\n",
            "Decision tree (simple) has: 129341 leaves.\n",
            "For our example row shown at top...\n",
            "The correct rating code (range is 0, 1, or 2) is: 2\n",
            "The tree's prediction is: [2]\n",
            "which is derived from the following probabilities from training data: [[0. 0. 1.]]\n",
            "Its prediction probabilities of [[0. 0. 1.]] are calculated by adding the bias of [[0.01753253 0.34318061 0.63928686]]\n",
            "to the following contributions, along each column (one per feature):\n",
            "[[[ 0.01319772  0.04378918 -0.05698689]\n",
            "  [-0.003097    0.23638683 -0.23328984]\n",
            "  [-0.00949668 -0.00857333  0.01807001]\n",
            "  [-0.01813657 -0.61478329  0.63291986]]]\n",
            "Calculated prediction is: [[3.46944695e-18 0.00000000e+00 1.00000000e+00]]\n",
            "Decision tree (simple) has the following feature importances overall: [0.19736139 0.23874735 0.20294539 0.36094587]\n",
            "\n",
            "For the same example row shown at top, the Random Forest's overall prediction is: [2]\n",
            "By majority vote of its 100 trees. Here are the first 10:\n",
            "\n",
            "Sample tree #1 from forest has a depth of: 44\n",
            "Sample tree #1 from forest has: 98886 leaves.\n",
            "For our example row shown at top...\n",
            "The correct rating code (range is 0, 1, or 2) is: 2\n",
            "The tree's prediction is: [1.]\n",
            "which is derived from the following probabilities from training data: [[0.  0.5 0.5]]\n",
            "Its prediction probabilities of [[0.  0.5 0.5]] are calculated by adding the bias of [[0.01785989 0.34236832 0.63977179]]\n",
            "to the following contributions, along each column (one per feature):\n",
            "[[[ 0.01219182  0.01368669 -0.02587852]\n",
            "  [ 0.004648   -0.12233358  0.11768558]\n",
            "  [-0.01224594  0.02363738 -0.01139144]\n",
            "  [-0.02245377  0.24264118 -0.22018741]]]\n",
            "Calculated prediction is: [[0.  0.5 0.5]]\n",
            "Sample tree #1 from forest has the following feature importances overall: [0.19121431 0.18506599 0.25126909 0.37245062]\n",
            "\n",
            "Sample tree #2 from forest has a depth of: 43\n",
            "Sample tree #2 from forest has: 99135 leaves.\n",
            "For our example row shown at top...\n",
            "The correct rating code (range is 0, 1, or 2) is: 2\n",
            "The tree's prediction is: [1.]\n",
            "which is derived from the following probabilities from training data: [[0. 1. 0.]]\n",
            "Its prediction probabilities of [[0. 1. 0.]] are calculated by adding the bias of [[0.01762356 0.3424541  0.63992234]]\n",
            "to the following contributions, along each column (one per feature):\n",
            "[[[ 0.01349689  0.06997689 -0.08347378]\n",
            "  [-0.00876057  0.56202055 -0.55325998]\n",
            "  [-0.00715966 -0.03302269  0.04018235]\n",
            "  [-0.01520022  0.05857115 -0.04337093]]]\n",
            "Calculated prediction is: [[0. 1. 0.]]\n",
            "Sample tree #2 from forest has the following feature importances overall: [0.18431221 0.18769411 0.24006858 0.3879251 ]\n",
            "\n",
            "Sample tree #3 from forest has a depth of: 46\n",
            "Sample tree #3 from forest has: 98544 leaves.\n",
            "For our example row shown at top...\n",
            "The correct rating code (range is 0, 1, or 2) is: 2\n",
            "The tree's prediction is: [1.]\n",
            "which is derived from the following probabilities from training data: [[0. 1. 0.]]\n",
            "Its prediction probabilities of [[0. 1. 0.]] are calculated by adding the bias of [[0.01764982 0.34355349 0.63879669]]\n",
            "to the following contributions, along each column (one per feature):\n",
            "[[[ 0.01458107  0.07927293 -0.093854  ]\n",
            "  [ 0.0032975  -0.0161412   0.0128437 ]\n",
            "  [-0.01368905  0.00660951  0.00707954]\n",
            "  [-0.02183935  0.58670527 -0.56486592]]]\n",
            "Calculated prediction is: [[0.00000000e+00 1.00000000e+00 1.11022302e-16]]\n",
            "Sample tree #3 from forest has the following feature importances overall: [0.18011109 0.16718404 0.23233386 0.42037101]\n",
            "\n",
            "Sample tree #4 from forest has a depth of: 44\n",
            "Sample tree #4 from forest has: 99673 leaves.\n",
            "For our example row shown at top...\n",
            "The correct rating code (range is 0, 1, or 2) is: 2\n",
            "The tree's prediction is: [2.]\n",
            "which is derived from the following probabilities from training data: [[0. 0. 1.]]\n",
            "Its prediction probabilities of [[0. 0. 1.]] are calculated by adding the bias of [[0.01732245 0.34306682 0.63961073]]\n",
            "to the following contributions, along each column (one per feature):\n",
            "[[[ 0.01088423  0.0673528  -0.07823703]\n",
            "  [ 0.0015113  -0.01964511  0.01813381]\n",
            "  [-0.01725408 -0.01857812  0.0358322 ]\n",
            "  [-0.0124639  -0.37219639  0.38466028]]]\n",
            "Calculated prediction is: [[3.46944695e-18 0.00000000e+00 1.00000000e+00]]\n",
            "Sample tree #4 from forest has the following feature importances overall: [0.18323005 0.13472311 0.28475109 0.39729575]\n",
            "\n",
            "Sample tree #5 from forest has a depth of: 46\n",
            "Sample tree #5 from forest has: 98722 leaves.\n",
            "For our example row shown at top...\n",
            "The correct rating code (range is 0, 1, or 2) is: 2\n",
            "The tree's prediction is: [2.]\n",
            "which is derived from the following probabilities from training data: [[0. 0. 1.]]\n",
            "Its prediction probabilities of [[0. 0. 1.]] are calculated by adding the bias of [[0.01754128 0.34295478 0.63950394]]\n",
            "to the following contributions, along each column (one per feature):\n",
            "[[[ 2.30785070e-04  4.12171847e-02 -4.14479698e-02]\n",
            "  [ 3.04529529e-03  6.08838167e-02 -6.39291120e-02]\n",
            "  [-1.19844049e-03 -6.02926068e-02  6.14910473e-02]\n",
            "  [-1.96189196e-02 -3.84763172e-01  4.04382092e-01]]]\n",
            "Calculated prediction is: [[3.46944695e-18 0.00000000e+00 1.00000000e+00]]\n",
            "Sample tree #5 from forest has the following feature importances overall: [0.18305632 0.15994148 0.25178989 0.4052123 ]\n",
            "\n",
            "Sample tree #6 from forest has a depth of: 44\n",
            "Sample tree #6 from forest has: 99248 leaves.\n",
            "For our example row shown at top...\n",
            "The correct rating code (range is 0, 1, or 2) is: 2\n",
            "The tree's prediction is: [2.]\n",
            "which is derived from the following probabilities from training data: [[0.   0.25 0.75]]\n",
            "Its prediction probabilities of [[0.   0.25 0.75]] are calculated by adding the bias of [[0.01726118 0.3432979  0.63944092]]\n",
            "to the following contributions, along each column (one per feature):\n",
            "[[[ 0.01365525  0.04639171 -0.06004695]\n",
            "  [-0.01571816 -0.01636901  0.03208717]\n",
            "  [-0.01813399 -0.04270431  0.0608383 ]\n",
            "  [ 0.00293572 -0.08061629  0.07768056]]]\n",
            "Calculated prediction is: [[0.   0.25 0.75]]\n",
            "Sample tree #6 from forest has the following feature importances overall: [0.18146508 0.18299634 0.24476931 0.39076926]\n",
            "\n",
            "Sample tree #7 from forest has a depth of: 45\n",
            "Sample tree #7 from forest has: 99291 leaves.\n",
            "For our example row shown at top...\n",
            "The correct rating code (range is 0, 1, or 2) is: 2\n",
            "The tree's prediction is: [2.]\n",
            "which is derived from the following probabilities from training data: [[0.   0.25 0.75]]\n",
            "Its prediction probabilities of [[0.   0.25 0.75]] are calculated by adding the bias of [[0.01719466 0.34343445 0.63937089]]\n",
            "to the following contributions, along each column (one per feature):\n",
            "[[[ 0.00753997  0.04947851 -0.05701848]\n",
            "  [-0.01781079  0.06841808 -0.05060729]\n",
            "  [ 0.00041245 -0.08381624  0.08340379]\n",
            "  [-0.00733629 -0.1275148   0.13485109]]]\n",
            "Calculated prediction is: [[0.   0.25 0.75]]\n",
            "Sample tree #7 from forest has the following feature importances overall: [0.180257   0.16581556 0.27700421 0.37692323]\n",
            "\n",
            "Sample tree #8 from forest has a depth of: 45\n",
            "Sample tree #8 from forest has: 98684 leaves.\n",
            "For our example row shown at top...\n",
            "The correct rating code (range is 0, 1, or 2) is: 2\n",
            "The tree's prediction is: [2.]\n",
            "which is derived from the following probabilities from training data: [[0. 0. 1.]]\n",
            "Its prediction probabilities of [[0. 0. 1.]] are calculated by adding the bias of [[0.01750277 0.3438581  0.63863913]]\n",
            "to the following contributions, along each column (one per feature):\n",
            "[[[ 0.00865576  0.06869098 -0.07734673]\n",
            "  [-0.02173     0.01690225  0.00482775]\n",
            "  [-0.0176854  -0.06174917  0.07943457]\n",
            "  [ 0.01325688 -0.36770216  0.35444528]]]\n",
            "Calculated prediction is: [[0. 0. 1.]]\n",
            "Sample tree #8 from forest has the following feature importances overall: [0.17786568 0.18240631 0.24524225 0.39448576]\n",
            "\n",
            "Sample tree #9 from forest has a depth of: 49\n",
            "Sample tree #9 from forest has: 98474 leaves.\n",
            "For our example row shown at top...\n",
            "The correct rating code (range is 0, 1, or 2) is: 2\n",
            "The tree's prediction is: [2.]\n",
            "which is derived from the following probabilities from training data: [[0. 0. 1.]]\n",
            "Its prediction probabilities of [[0. 0. 1.]] are calculated by adding the bias of [[0.01762356 0.3423263  0.64005014]]\n",
            "to the following contributions, along each column (one per feature):\n",
            "[[[ 0.01244312  0.0468182  -0.05926132]\n",
            "  [ 0.00384629 -0.03540618  0.03155988]\n",
            "  [-0.00925554 -0.03496495  0.0442205 ]\n",
            "  [-0.02465743 -0.31877337  0.3434308 ]]]\n",
            "Calculated prediction is: [[0. 0. 1.]]\n",
            "Sample tree #9 from forest has the following feature importances overall: [0.17914862 0.19892009 0.24386797 0.37806333]\n",
            "\n",
            "Sample tree #10 from forest has a depth of: 45\n",
            "Sample tree #10 from forest has: 98815 leaves.\n",
            "For our example row shown at top...\n",
            "The correct rating code (range is 0, 1, or 2) is: 2\n",
            "The tree's prediction is: [2.]\n",
            "which is derived from the following probabilities from training data: [[0. 0. 1.]]\n",
            "Its prediction probabilities of [[0. 0. 1.]] are calculated by adding the bias of [[0.01788965 0.34397889 0.63813145]]\n",
            "to the following contributions, along each column (one per feature):\n",
            "[[[ 0.00733629 -0.0186999   0.01136361]\n",
            "  [-0.00277278  0.06740172 -0.06462894]\n",
            "  [-0.02614843 -0.05016702  0.07631545]\n",
            "  [ 0.00369526 -0.34251369  0.33881843]]]\n",
            "Calculated prediction is: [[3.46944695e-18 0.00000000e+00 1.00000000e+00]]\n",
            "Sample tree #10 from forest has the following feature importances overall: [0.18333744 0.14083812 0.24983446 0.42598998]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}